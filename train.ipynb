{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video intelegence.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Z8NPH9Kw6xUyHkgO69NR4jjwiITVD8Jq",
      "authorship_tag": "ABX9TyMtTHzU0LQQLVh5qII/0iKC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/up1512001/1657aac9693accd561be484a1a7c0d3a/video-intelegence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1oJZWk7Lqfym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdda1e8-ca7f-4a0a-8b87-7e932a44121e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip \"/content/drive/MyDrive/6th sem project/Avenue_Dataset.zip\" \"/content/project code\""
      ],
      "metadata": {
        "id": "rE74vfsRrKS1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array,load_img\n",
        "import numpy as np\n",
        "import glob\n",
        "import os \n",
        "import cv2\n",
        "\n",
        "from keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import imutils"
      ],
      "metadata": {
        "id": "SmZtfHxes-X0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_image=[]\n",
        "train_path='/content/drive/MyDrive/Colab Notebooks/train_video_6th_project'\n",
        "fps=5\n",
        "train_videos=os.listdir(train_path)\n",
        "# print(train_videos)\n",
        "train_images_path=train_path+'/frames'\n",
        "os.makedirs(train_images_path)\n",
        "# print(os.listdir(train_images_path))\n",
        "def store_inarray(image_path):\n",
        "    image=load_img(image_path)\n",
        "    image=img_to_array(image)\n",
        "    image=cv2.resize(image, (227,227), interpolation = cv2.INTER_AREA)\n",
        "    gray=0.2989*image[:,:,0]+0.5870*image[:,:,1]+0.1140*image[:,:,2]\n",
        "    store_image.append(gray)"
      ],
      "metadata": {
        "id": "u_oUYecUtyqB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from logging import currentframe\n",
        "currentframe=0\n",
        "for video in train_videos:\n",
        "    cap = cv2.VideoCapture('{}/{}'.format(train_path,video))\n",
        "    while(True):\n",
        "      ret,frame = cap.read()\n",
        "      if ret:\n",
        "        x = '/content/train dir/'+str(currentframe)+'.jpg'\n",
        "        # print(x)\n",
        "        cv2.imwrite(x,frame)\n",
        "        currentframe+=1\n",
        "      else:\n",
        "        break\n",
        "    # os.system( 'ffmpeg -i {}/{} -r 1/{}  {}/frames/%03d.jpg'.format(train_path,video,fps,train_path))\n",
        "    # print('ffmpeg -i {}/{} -r 1/{}  {}/frames/%03d.jpg'.format(train_path,video,fps,train_path))\n",
        "    # os.system('{}/{} ')\n",
        "    # print(video)\n"
      ],
      "metadata": {
        "id": "5nkALssUuCsy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_path = '/content/train dir'\n",
        "images=os.listdir(train_images_path)\n",
        "# images.remove('.ipynb_checkpoints')\n",
        "  # print(images)\n",
        "for image in images:\n",
        "    image_path=train_images_path + '/' + image\n",
        "    store_inarray(image_path)\n",
        "    # print(image.shape)"
      ],
      "metadata": {
        "id": "sVgT8UsFvegc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(os.listdir('/content/train dir'))"
      ],
      "metadata": {
        "id": "p7RWJTVvvtwF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_image=np.array(store_image)\n",
        "a,b,c=store_image.shape\n",
        "# print(store_image.shape)\n",
        "store_image.resize(b,c,a)\n",
        "store_image=(store_image-store_image.mean())/(store_image.std())\n",
        "store_image=np.clip(store_image,0,1)\n",
        "np.save('training.npy',store_image)"
      ],
      "metadata": {
        "id": "P4joM-XWwMnS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stae_model=Sequential()\n",
        "\n",
        "stae_model.add(Conv3D(filters=128,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',input_shape=(227,227,10,1),activation='tanh'))\n",
        "stae_model.add(Conv3D(filters=64,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\n",
        "stae_model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,padding='same',dropout=0.4,recurrent_dropout=0.3,return_sequences=True))\n",
        "stae_model.add(ConvLSTM2D(filters=32,kernel_size=(3,3),strides=1,padding='same',dropout=0.3,return_sequences=True))\n",
        "stae_model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,return_sequences=True, padding='same',dropout=0.5))\n",
        "stae_model.add(Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\n",
        "stae_model.add(Conv3DTranspose(filters=1,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',activation='tanh'))\n",
        "\n",
        "stae_model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "R3TeBO-SwQXq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "training_data=np.load('training.npy')\n",
        "frames=training_data.shape[2]\n",
        "frames=frames-frames%10\n",
        "\n",
        "training_data=training_data[:,:,:frames]\n",
        "training_data=training_data.reshape(-1,227,227,10)\n",
        "training_data=np.expand_dims(training_data,axis=4)\n",
        "target_data=training_data.copy()\n",
        "\n",
        "epochs=5\n",
        "batch_size=1\n",
        "\n",
        "callback_save = ModelCheckpoint(\"saved_model.h5\", monitor=\"mean_squared_error\", save_best_only=True)\n",
        "\n",
        "callback_early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "stae_model.fit(training_data,target_data, batch_size=batch_size, epochs=epochs, callbacks = [callback_save,callback_early_stopping])\n",
        "stae_model.save(\"saved_model.h5\")"
      ],
      "metadata": {
        "id": "DRG0KpM8wr-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365deffd-5bfa-4a3f-98ee-45e63a836f6c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1532/1532 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.7183WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "1532/1532 [==============================] - 6123s 4s/step - loss: 0.0838 - accuracy: 0.7183\n",
            "Epoch 2/5\n",
            "1532/1532 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.7374WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "1532/1532 [==============================] - 7186s 5s/step - loss: 0.0690 - accuracy: 0.7374\n",
            "Epoch 3/5\n",
            "1532/1532 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.7380WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "1532/1532 [==============================] - 7417s 5s/step - loss: 0.0683 - accuracy: 0.7380\n",
            "Epoch 4/5\n",
            "1532/1532 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.7650WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "1532/1532 [==============================] - 7334s 5s/step - loss: 0.0385 - accuracy: 0.7650\n",
            "Epoch 5/5\n",
            "1532/1532 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.7758WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "1532/1532 [==============================] - 7315s 5s/step - loss: 0.0287 - accuracy: 0.7758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kQdkktVuwuUN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_loss(x1,x2):\n",
        "    difference=x1-x2\n",
        "    a,b,c,d,e=difference.shape\n",
        "    n_samples=a*b*c*d*e\n",
        "    sq_difference=difference**2\n",
        "    Sum=sq_difference.sum()\n",
        "    distance=np.sqrt(Sum)\n",
        "    mean_distance=distance/n_samples\n",
        "    return mean_distance\n",
        "    "
      ],
      "metadata": {
        "id": "8yOKUdGw4Bx1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.load_model(\"saved_model.h5\")\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Colab Notebooks/train_video_6th_project/test/09.avi\")\n",
        "print(cap.isOpened())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPGFll7f4EIo",
        "outputId": "72894be2-d1ee-4c44-bd2e-771f0af7a741"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "Eyae6YX66Fm0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cap.isOpened():\n",
        "    imagedump=[]\n",
        "    ret,frame=cap.read()\n",
        "    for i in range(10):\n",
        "        ret,frame=cap.read()\n",
        "        image = imutils.resize(frame,width=700,height=600)\n",
        "        frame=cv2.resize(frame, (227,227), interpolation = cv2.INTER_AREA)\n",
        "        gray=0.2989*frame[:,:,0]+0.5870*frame[:,:,1]+0.1140*frame[:,:,2]\n",
        "        gray=(gray-gray.mean())/gray.std()\n",
        "        gray=np.clip(gray,0,1)\n",
        "        imagedump.append(gray)\n",
        "    imagedump=np.array(imagedump)\n",
        "    imagedump.resize(227,227,10)\n",
        "    imagedump=np.expand_dims(imagedump,axis=0)\n",
        "    imagedump=np.expand_dims(imagedump,axis=4)\n",
        "    output=model.predict(imagedump)\n",
        "    loss=mean_squared_loss(imagedump,output)\n",
        "    if frame.any()==None:\n",
        "        print(\"none\")\n",
        "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
        "        break\n",
        "    if loss>0.00068:\n",
        "        print('Abnormal Event Detected')\n",
        "        cv2.putText(image,\"Abnormal Event\",(100,80),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),4)\n",
        "    cv2_imshow(image)\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "MOBfRaAZ4H36",
        "outputId": "f5be0837-1bc1-41c5-88d6-a9a436f157bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-753767ca696d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimagedump\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model/my_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvDvzAX6535p",
        "outputId": "84e4d9a2-bb1c-4ab3-f48d-aec9c7e91fc4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls saved_model/my_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA67LAJH9bwJ",
        "outputId": "ffcbad17-61a3-48a8-b529-cf0e94b65c8a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Create a new model instance\n",
        "# model = create_model()\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Evaluate the model\n",
        "# loss, acc = model.evaluate(, test_labels, verbose=2)\n",
        "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC3uuXYr9pD1",
        "outputId": "10088097-ecfd-410b-e620-f9e4a080c100"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f12694a0650>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "qHJ_o4j5_ao7",
        "outputId": "aee41814-86f9-4030-af26-196871b8876a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a9712b53aa55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rccL_PPxHTMD",
        "outputId": "fcf1fd59-83b5-4531-ae34-237bd3f252de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'tensorflow' from '/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SXt5Ioi7HfxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}